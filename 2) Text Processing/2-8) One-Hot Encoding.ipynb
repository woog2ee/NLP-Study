{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "corrected-vault",
   "metadata": {},
   "source": [
    "# 1. 원-핫 인코딩(One-Hot Encoding)이란?\n",
    "단어 집합의 크기를 벡터의 차원으로 해서 표현   \n",
    "단어 집합(vocabulary): 단어의 변형 형태를 포함한 서로 다른 단어들의 집합    \n",
    "1. 정수 인코딩: 각 단어에 고유 인덱스 부여\n",
    "2. 이후 원-핫 인코딩: 표현할 단어 인덱스에는 1, 다른 인덱스에는 0 부여"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "earned-limit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['나', '는', '자연어', '처리', '를', '배운다']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "token = okt.morphs(\"나는 자연어 처리를 배운다\")\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "signed-relaxation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'나': 0, '는': 1, '자연어': 2, '처리': 3, '를': 4, '배운다': 5}\n"
     ]
    }
   ],
   "source": [
    "word2index = {}\n",
    "for voca in token:\n",
    "    if voca not in word2index.keys():\n",
    "        word2index[voca] = len(word2index)\n",
    "print(word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "reported-publisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(word, word2index):\n",
    "    one_hot_vector = [0] * (len(word2index))\n",
    "    index = word2index[word]\n",
    "    one_hot_vector[index] = 1\n",
    "    return one_hot_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "german-pepper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 0, 0, 0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoding(\"자연어\", word2index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-evening",
   "metadata": {},
   "source": [
    "# 2. 케라스(Keras)를 이용한 원-핫 인코딩(One-Hot Encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "expanded-geography",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"나랑 점심 먹으러 갈래 점심 메뉴는 햄버거 갈래 갈래 햄버거 최고야\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "gentle-perfume",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'갈래': 1, '점심': 2, '햄버거': 3, '나랑': 4, '먹으러': 5, '메뉴는': 6, '최고야': 7}\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts([text])\n",
    "print(t.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "stunning-coalition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 5, 1, 6, 3, 7]\n"
     ]
    }
   ],
   "source": [
    "sub_text = \"점심 먹으러 갈래 메뉴는 햄버거 최고야\"\n",
    "encoded = t.texts_to_sequences([sub_text])[0]\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "royal-trader",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# to_categorical()은 인코딩된 결과로부터 원-핫 인코딩 수행\n",
    "one_hot = to_categorical(encoded)\n",
    "print(one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-angel",
   "metadata": {},
   "source": [
    "# 3. 원-핫 인코딩(One-Hot Encoding)의 한계\n",
    "단어 개수가 늘수록 벡터 저장을 위해 필요한 공간(벡터의 차원)이 계속 늘어남   \n",
    "단어의 유사도를 표현하지 못하며, 이는 검색 시스템에서 문제 야기   \n",
    "\n",
    "이를 해결하고자 단어의 잠재 의미를 반영해 다차원 공간에 벡터화 하는 기법\n",
    "1. 카운트 기반 벡터화하는 LSA, HAL\n",
    "2. 예측 기반 벡터화하는 NNLM, RNNLM, Word2Vec, FastText\n",
    "3. 카운트와 예측 기반 모두를 사용하는 GloVe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
