{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "northern-listening",
   "metadata": {},
   "source": [
    "# 1. 순환 신경망(Recurrent Neural Network, RNN)\n",
    "입출력을 시퀀스 단위 처리로 가장 단순한 형태인 Vanilla RNN    \n",
    "은닉층 노드 활성화 함수로 나온 값을 다시 은닉층 노드 입력으로 보냄   \n",
    "은닉 상태(hidden state)는 셀이 출력층 방향 혹은 다음 셀에게 보내는 값   \n",
    "![RNN1](https://wikidocs.net/images/page/22886/rnn_image2_ver3.PNG \"RNN1\")\n",
    "\n",
    "은닉층과 출력층 사이 관계\n",
    "$$h_{t} = tanh(W_{x}x_{t} + W_{h}h_{t-1} + b)$$\n",
    "$$y_{t} = f(W_{y}h_{t} + b)$$\n",
    "![RNN2](https://wikidocs.net/images/page/22886/rnn_image4_ver2.PNG \"RNN2\")\n",
    "\n",
    "은닉층 연산을 벡터와 행렬 연산으로 표현\n",
    "![RNN3](https://wikidocs.net/images/page/22886/rnn_images4-5.PNG \"RNN3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decent-equality",
   "metadata": {},
   "source": [
    "# 2. Keras로 RNN 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "different-status",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN층 추가\n",
    "# model.add(SimpleRNN(hidden_size))\n",
    "\n",
    "# 인자 추가\n",
    "# model.add(SimpleRNN(hidden_size, input_shape=(timesteps, input_dim)))\n",
    "# model.add(SimpleRNN(hidden_size, input_length=M, input_dim=N))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bearing-attraction",
   "metadata": {},
   "source": [
    "![RNN4](https://wikidocs.net/images/page/22886/rnn_image6between7.PNG \"RNN4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "composed-camping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn (SimpleRNN)       (None, 3)                 42        \n",
      "=================================================================\n",
      "Total params: 42\n",
      "Trainable params: 42\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(3, input_shape=(2,10)))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "textile-savannah",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_1 (SimpleRNN)     (8, 3)                    42        \n",
      "=================================================================\n",
      "Total params: 42\n",
      "Trainable params: 42\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(3, batch_input_shape=(8,2,10)))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "varied-spoke",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_2 (SimpleRNN)     (8, 2, 3)                 42        \n",
      "=================================================================\n",
      "Total params: 42\n",
      "Trainable params: 42\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# return_sequences=True로 모든 시점에서 은닉 상태 반환\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(3, batch_input_shape=(8,2,10), return_sequences=True))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hispanic-brother",
   "metadata": {},
   "source": [
    "# 3. 파이썬으로 RNN 구현하기\n",
    "$$h_{t} = tanh(W_{x}X_{t} + W_{h}h_{t-1} + b)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pediatric-buffalo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "timesteps = 10 # 시점 수(문장 길이)\n",
    "input_dim = 4 # 입력 차원(단어 벡터 차원)\n",
    "hidden_size = 8 # 은닉 상태 크기(메모리 셀 용량)\n",
    "\n",
    "inputs = np.random.random((timesteps, input_dim))\n",
    "\n",
    "hidden_state_t = np.zeros((hidden_size,))\n",
    "print(hidden_state_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "alone-portal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 4)\n",
      "(8, 8)\n",
      "(8,)\n"
     ]
    }
   ],
   "source": [
    "Wx = np.random.random((hidden_size, input_dim))\n",
    "Wh = np.random.random((hidden_size, hidden_size))\n",
    "b = np.random.random((hidden_size,))\n",
    "\n",
    "print(np.shape(Wx))\n",
    "print(np.shape(Wh))\n",
    "print(np.shape(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "still-emphasis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 8)\n",
      "(2, 8)\n",
      "(3, 8)\n",
      "(4, 8)\n",
      "(5, 8)\n",
      "(6, 8)\n",
      "(7, 8)\n",
      "(8, 8)\n",
      "(9, 8)\n",
      "(10, 8)\n",
      "[[0.97628083 0.67602303 0.96997059 0.93430302 0.96701    0.91284672\n",
      "  0.97984179 0.88847663]\n",
      " [0.99999094 0.99300521 0.9999655  0.99996157 0.99998371 0.99969754\n",
      "  0.99996782 0.99932906]\n",
      " [0.999998   0.99680932 0.9999888  0.99998672 0.99999787 0.99975953\n",
      "  0.99999087 0.99992721]\n",
      " [0.99999808 0.99767547 0.99998743 0.99999155 0.99999671 0.99974653\n",
      "  0.99998634 0.99994876]\n",
      " [0.99999901 0.99579427 0.9999949  0.99998606 0.99999858 0.99990392\n",
      "  0.99999675 0.99979522]\n",
      " [0.99999484 0.99755781 0.99998989 0.99999077 0.99999736 0.99963869\n",
      "  0.99997797 0.99987305]\n",
      " [0.99999941 0.99730381 0.99999749 0.99999075 0.99999952 0.9999115\n",
      "  0.99999827 0.99989318]\n",
      " [0.99999943 0.99891505 0.99999798 0.99999749 0.99999909 0.99990932\n",
      "  0.99999603 0.99993346]\n",
      " [0.99999974 0.99812306 0.99999743 0.99999468 0.99999931 0.999936\n",
      "  0.99999848 0.99995191]\n",
      " [0.99999908 0.99695384 0.99999214 0.99998831 0.99999848 0.99984917\n",
      "  0.99999549 0.99994156]]\n"
     ]
    }
   ],
   "source": [
    "total_hidden_states = []\n",
    "\n",
    "for input_t in inputs:\n",
    "    output_t = np.tanh(np.dot(Wx,input_t) + np.dot(Wh,hidden_state_t) + b)\n",
    "    total_hidden_states.append(list(output_t))\n",
    "    print(np.shape(total_hidden_states))\n",
    "    \n",
    "    hidden_state_t = output_t\n",
    "    \n",
    "total_hidden_states = np.stack(total_hidden_states, axis=0)\n",
    "print(total_hidden_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dramatic-copyright",
   "metadata": {},
   "source": [
    "# 4. 깊은 순환 신경망(Deep RNN)\n",
    "은닉층 다수 생성 가능\n",
    "![RNN5](https://wikidocs.net/images/page/22886/rnn_image4.5_finalPNG.PNG \"RNN5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "thick-difficulty",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(hidden_size, return_sequences=True))\n",
    "model.add(SimpleRNN(hidden_size, return_sequences=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aquatic-differential",
   "metadata": {},
   "source": [
    "# 5. 양방향 순환 신경망(Bidirectional RNN)\n",
    "특정 시점 출력값을 예측시 이전 시점뿐만 아니라 이후 시점으로도 예측   \n",
    "이후 시점의 은닉 상태로 현재 은닉 상태를 계산하는 셀 추가\n",
    "![Bidirectional RNN](https://wikidocs.net/images/page/22886/rnn_image5_ver2.PNG \"Bidirectional RNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "grave-citation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Bidirectional\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(SimpleRNN(hidden_size, return_sequences=True), input_shape=(timesteps, input_dim)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decent-assembly",
   "metadata": {},
   "source": [
    "Deep Bidirectional RNN 역시 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "recent-international",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(SimpleRNN(hidden_size, return_sequences=True), input_shape=(timesteps,input_dim)))\n",
    "model.add(Bidirectional(SimpleRNN(hidden_size, return_sequences=True)))\n",
    "model.add(Bidirectional(SimpleRNN(hidden_size, return_sequences=True)))\n",
    "model.add(Bidirectional(SimpleRNN(hidden_size, return_sequences=True)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
