{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "directed-demonstration",
   "metadata": {},
   "source": [
    "# 1. Latent Dirichlet Allocation\n",
    "LDA는 문서 생성 과정을 역추적    \n",
    "'문서는 토픽 혼합으로 구성되며, 토픽은 확률분포에 기반해 단어를 생성한다'는 가정   \n",
    "토픽 제목을 정하진 않으나 결과로부터 토픽 판단 가능   \n",
    "\n",
    "<null>|내용\n",
    ":--|:--\n",
    "문서1|저는 사과랑 바나나를 먹어요   \n",
    "문서2|우리는 귀여운 강아지가 좋아요   \n",
    "문서3|저의 깜찍하고 귀여운 강아지가 바나나를 먹어요   \n",
    "\n",
    "<null>|토픽 분포\n",
    ":--|:--\n",
    "문서1|토픽 A 100%   \n",
    "문서2|토픽 B 100%   \n",
    "문서3|토픽 B 60%, 토픽 A 40%   \n",
    "\n",
    "<null>|토픽 단어 분포\n",
    ":--|:--\n",
    "토픽A|사과 20%, 바나나 40%, 먹어요 40%, 귀여운 0%, 강아지 0%, 깜직하고 0%, 좋아요 0%   \n",
    "토픽B|사과 0%, 바나나 0%, 먹어요 0%, 귀여운 33%, 강아지 33%, 깜찍하고 16%, 좋아요 16%   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-committee",
   "metadata": {},
   "source": [
    "# 2. LDA 가정\n",
    "> **1) 사용할 단어 개수를 정함**   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detailed-immigration",
   "metadata": {},
   "source": [
    "> **2) 사용할 토픽 혼합을 확률분포에 기반해 결정**   \n",
    "> 예) 토픽이 2개면 강아지 토픽 60%, 과일 토픽 40%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valued-headline",
   "metadata": {},
   "source": [
    "> **3) 문서에 사용할 각 단어를 정함**   \n",
    "> 1. 토픽 분포에서 토픽을 확률적으로 선택   \n",
    "> 2. 선택 토픽에서 단어 출현 확률분포에 기반해 문서에 사용할 단어를 고름   \n",
    "> 예) 강아지 토픽에서는 33% 확률로 단어 '강아지' 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moved-programmer",
   "metadata": {},
   "source": [
    "# 3. LDA 수행\n",
    "> **1) 토픽 개수 k 입력**   \n",
    "> 토픽 k개가 전체 문서에 분포됨을 가정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historic-freeware",
   "metadata": {},
   "source": [
    "> **2) 모든 단어를 한 토픽에 랜덤 할당**   \n",
    "> 각 문서는 토픽을, 토픽은 단어 분포를 갖게 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "related-connectivity",
   "metadata": {},
   "source": [
    "> **3) 모든 단어에 대해 iteration**   \n",
    "> 해당 단어는 잘못된 토픽, 다른 단어는 올바른 토픽에 할당됨을 가정해 **해당 단어의 토픽 재할당**   \n",
    "\n",
    "> 예) 문서1 단어 apple 토픽 결정   \n",
    "\n",
    "> doc1|apple|banana|apple|dog|dog\n",
    "> :-:|:-:|:-:|:-:|:-:|:-:\n",
    "> topic|B|B|???|A|A\n",
    "\n",
    "> doc2|cute|book|king|apple|apple\n",
    "> :-:|:-:|:-:|:-:|:-:|:-:\n",
    "> topic|B|B|B|B|B\n",
    "\n",
    "> 기준1: 해당 문서에서 전체 단어 토픽 확인   \n",
    "> 단어 apple은 어떤 토픽에도 속할 수 있음   \n",
    "\n",
    "> doc1|**apple**|**banana**|apple|**dog**|**dog**\n",
    "> :-:|:-:|:-:|:-:|:-:|:-:\n",
    "> topic|**B**|**B**|???|**A**|**A**\n",
    "\n",
    "> 기준2: 전체 문서에서 해당 단어 토픽 확인   \n",
    "> 단어 apple은 토픽 B일 가능성이 높음\n",
    "\n",
    "> doc1|**apple**|banana|**apple**|dog|dog\n",
    "> :-:|:-:|:-:|:-:|:-:|:-:\n",
    "> topic|**B**|B|**???**|A|A\n",
    "\n",
    "> doc2|cute|book|king|**apple**|**apple**\n",
    "> :-:|:-:|:-:|:-:|:-:|:-:\n",
    "> topic|B|B|B|**B**|**B**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diagnostic-tower",
   "metadata": {},
   "source": [
    "# 4. LSA와 LDA \n",
    "LSA는 SVD의 근접 단어들을 토픽으로 묶음   \n",
    "LDA는 **문서의 특정 토픽 존재 확률**과 **단어가 특정 토픽에 속할 확률**을 추정해 토픽 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consolidated-hebrew",
   "metadata": {},
   "source": [
    "# 5. 실습\n",
    "> **1) 정수 인코딩과 단어 집합 생성**   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "regular-neutral",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-aedc00f00276>:11: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  news_df['clean_doc'] = news_df['document'].str.replace(\"[^a-zA-Z]\", \" \")\n"
     ]
    }
   ],
   "source": [
    "# 뉴스그룹 데이터 로드\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\n",
    "documents = dataset.data\n",
    "\n",
    "# 텍스트 전처리\n",
    "news_df = pd.DataFrame({'document':documents})\n",
    "\n",
    "news_df['clean_doc'] = news_df['document'].str.replace(\"[^a-zA-Z]\", \" \")\n",
    "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n",
    "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: x.lower())\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "tokenized_doc = news_df['clean_doc'].apply(lambda x: x.split())\n",
    "tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "lightweight-maintenance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [well, sure, story, seem, biased, disagree, st...\n",
       "1    [yeah, expect, people, read, actually, accept,...\n",
       "2    [although, realize, principle, strongest, poin...\n",
       "3    [notwithstanding, legitimate, fuss, proposal, ...\n",
       "4    [well, change, scoring, playoff, pool, unfortu...\n",
       "Name: clean_doc, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_doc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "silent-vietnam",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(52, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 2), (67, 1), (68, 1), (69, 1), (70, 1), (71, 2), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 2), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 1), (85, 2), (86, 1), (87, 1), (88, 1), (89, 1)]\n"
     ]
    }
   ],
   "source": [
    "# 정수 인코딩 및 단어 빈도수 기록\n",
    "from gensim import corpora \n",
    "dictionary = corpora.Dictionary(tokenized_doc)\n",
    "corpus = [dictionary.doc2bow(text) for text in tokenized_doc]\n",
    "print(corpus[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "advanced-connection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accept\n"
     ]
    }
   ],
   "source": [
    "print(dictionary[55])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "brown-election",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64281"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legitimate-paraguay",
   "metadata": {},
   "source": [
    "> **2) LDA 모델 훈련**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "alleged-climb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.021*\"window\" + 0.012*\"motif\" + 0.011*\"server\" + 0.009*\"application\"')\n",
      "(1, '0.011*\"people\" + 0.009*\"would\" + 0.007*\"government\" + 0.005*\"state\"')\n",
      "(2, '0.015*\"rockefeller\" + 0.015*\"circuits\" + 0.008*\"suck\" + 0.007*\"believer\"')\n",
      "(3, '0.028*\"output\" + 0.025*\"entry\" + 0.013*\"line\" + 0.013*\"build\"')\n",
      "(4, '0.016*\"privacy\" + 0.014*\"technology\" + 0.013*\"encryption\" + 0.010*\"information\"')\n",
      "(5, '0.020*\"would\" + 0.017*\"like\" + 0.015*\"know\" + 0.010*\"think\"')\n",
      "(6, '0.041*\"file\" + 0.025*\"program\" + 0.018*\"windows\" + 0.016*\"files\"')\n",
      "(7, '0.018*\"game\" + 0.016*\"year\" + 0.016*\"team\" + 0.012*\"games\"')\n",
      "(8, '0.016*\"period\" + 0.013*\"play\" + 0.010*\"power\" + 0.009*\"goal\"')\n",
      "(9, '0.012*\"guns\" + 0.008*\"cars\" + 0.008*\"rate\" + 0.008*\"firearms\"')\n",
      "(10, '0.015*\"armenian\" + 0.014*\"said\" + 0.014*\"armenians\" + 0.012*\"people\"')\n",
      "(11, '0.012*\"cross\" + 0.010*\"kent\" + 0.009*\"plane\" + 0.009*\"slave\"')\n",
      "(12, '0.010*\"mormons\" + 0.009*\"mormon\" + 0.008*\"francis\" + 0.007*\"weiss\"')\n",
      "(13, '0.018*\"drive\" + 0.014*\"card\" + 0.012*\"system\" + 0.011*\"disk\"')\n",
      "(14, '0.010*\"people\" + 0.009*\"would\" + 0.006*\"jesus\" + 0.006*\"think\"')\n",
      "(15, '0.032*\"space\" + 0.013*\"nasa\" + 0.007*\"data\" + 0.007*\"center\"')\n",
      "(16, '0.010*\"system\" + 0.010*\"keys\" + 0.009*\"chip\" + 0.008*\"public\"')\n",
      "(17, '0.014*\"mail\" + 0.014*\"available\" + 0.012*\"information\" + 0.010*\"please\"')\n",
      "(18, '0.009*\"neutral\" + 0.007*\"compass\" + 0.006*\"weaver\" + 0.006*\"ground\"')\n",
      "(19, '0.015*\"health\" + 0.012*\"medical\" + 0.008*\"disease\" + 0.007*\"pain\"')\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "NUM_TOPICS = 20\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=NUM_TOPICS, id2word=dictionary, passes=15)\n",
    "topics = ldamodel.print_topics(num_words=4)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affecting-trade",
   "metadata": {},
   "source": [
    "> **4) 문서 토픽 분포 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "rising-perfume",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 번째 문서의 topic 비율은 [(1, 0.31363308), (2, 0.07571052), (4, 0.018783059), (10, 0.13983168), (14, 0.40638313), (18, 0.034168553)]\n",
      "1 번째 문서의 topic 비율은 [(5, 0.44155407), (7, 0.06759918), (14, 0.44030643), (16, 0.029455788)]\n",
      "2 번째 문서의 topic 비율은 [(1, 0.48116532), (5, 0.29229742), (10, 0.06274679), (13, 0.102307916), (14, 0.04893566)]\n",
      "3 번째 문서의 topic 비율은 [(0, 0.18933143), (1, 0.08074704), (4, 0.095139876), (5, 0.28190193), (13, 0.05666134), (16, 0.28526068)]\n",
      "4 번째 문서의 topic 비율은 [(6, 0.09158193), (7, 0.87507576)]\n"
     ]
    }
   ],
   "source": [
    "for i, topic_list in enumerate(ldamodel[corpus]):\n",
    "    if i == 5:\n",
    "        break\n",
    "    print(i, '번째 문서의 topic 비율은', topic_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "moral-configuration",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_topictable_per_doc(ldamodel, corpus):\n",
    "    topic_table = pd.DataFrame()\n",
    "    \n",
    "    for i, topic_list in enumerate(ldamodel[corpus]):\n",
    "        doc = topic_list[0] if ldamodel.per_word_topics else topic_list\n",
    "        doc = sorted(doc, key=lambda x: (x[1]), reverse=True)\n",
    "        \n",
    "        for j, (topic_num, prop_topic) in enumerate(doc):\n",
    "            if j == 0:\n",
    "                topic_table = topic_table.append(pd.Series([int(topic_num), round(prop_topic,4), \n",
    "                                                            topic_list]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "    return(topic_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "smooth-applicant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>문서 번호</th>\n",
       "      <th>가장 비중이 높은 토픽</th>\n",
       "      <th>가장 높은 토픽의 비중</th>\n",
       "      <th>각 토픽의 비중</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.4064</td>\n",
       "      <td>[(1, 0.31362814), (2, 0.07571132), (4, 0.01878...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.4416</td>\n",
       "      <td>[(5, 0.44157615), (7, 0.06758654), (14, 0.4402...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4812</td>\n",
       "      <td>[(1, 0.48115027), (5, 0.29228505), (10, 0.0627...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.2852</td>\n",
       "      <td>[(0, 0.18951279), (1, 0.08000005), (4, 0.09540...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.8751</td>\n",
       "      <td>[(6, 0.09158051), (7, 0.87507725)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.6073</td>\n",
       "      <td>[(5, 0.1592673), (14, 0.6072812), (15, 0.196451)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.5040</td>\n",
       "      <td>[(0, 0.029830465), (1, 0.024769574), (3, 0.077...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.3552</td>\n",
       "      <td>[(1, 0.20315629), (5, 0.3552327), (10, 0.20329...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4103</td>\n",
       "      <td>[(1, 0.41026), (5, 0.28741318), (8, 0.06453287...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.9136</td>\n",
       "      <td>[(5, 0.91355413), (8, 0.015192115), (16, 0.059...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   문서 번호  가장 비중이 높은 토픽  가장 높은 토픽의 비중  \\\n",
       "0      0          14.0        0.4064   \n",
       "1      1           5.0        0.4416   \n",
       "2      2           1.0        0.4812   \n",
       "3      3          16.0        0.2852   \n",
       "4      4           7.0        0.8751   \n",
       "5      5          14.0        0.6073   \n",
       "6      6          13.0        0.5040   \n",
       "7      7           5.0        0.3552   \n",
       "8      8           1.0        0.4103   \n",
       "9      9           5.0        0.9136   \n",
       "\n",
       "                                            각 토픽의 비중  \n",
       "0  [(1, 0.31362814), (2, 0.07571132), (4, 0.01878...  \n",
       "1  [(5, 0.44157615), (7, 0.06758654), (14, 0.4402...  \n",
       "2  [(1, 0.48115027), (5, 0.29228505), (10, 0.0627...  \n",
       "3  [(0, 0.18951279), (1, 0.08000005), (4, 0.09540...  \n",
       "4                 [(6, 0.09158051), (7, 0.87507725)]  \n",
       "5  [(5, 0.1592673), (14, 0.6072812), (15, 0.196451)]  \n",
       "6  [(0, 0.029830465), (1, 0.024769574), (3, 0.077...  \n",
       "7  [(1, 0.20315629), (5, 0.3552327), (10, 0.20329...  \n",
       "8  [(1, 0.41026), (5, 0.28741318), (8, 0.06453287...  \n",
       "9  [(5, 0.91355413), (8, 0.015192115), (16, 0.059...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topictable = make_topictable_per_doc(ldamodel, corpus)\n",
    "topictable = topictable.reset_index()\n",
    "topictable.columns = ['문서 번호', '가장 비중이 높은 토픽', '가장 높은 토픽의 비중', '각 토픽의 비중']\n",
    "topictable[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
