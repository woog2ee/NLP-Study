{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "vietnamese-layer",
   "metadata": {},
   "source": [
    "# 1. 코퍼스에서 카운트하지 못할 경우 감소   \n",
    "확률을 계산할 문장이 길면 코퍼스에 없는 경우가 많음   \n",
    "지나친 일반화를 막는 선에서 참고 단어를 줄여, 시퀀스 카운트 확률을 높임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-cannon",
   "metadata": {},
   "source": [
    "# 2. N-gram\n",
    "카운트 기반 통계적 접근으로 SLM의 일종   \n",
    "n개의 연속적 단어 뭉치로 끊어 한 토큰으로 간주   \n",
    "다음 단어 예측은 n-1개 단어에만 의존 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "republican-infrastructure",
   "metadata": {},
   "source": [
    "# 3. N-gram Language Model 한계   \n",
    "> **1) Sparsity Problem**   \n",
    "> 일부 단어만 파악해 현실적 카운트 확률은 높지만 희소 문제는 여전   \n",
    "> 분모, 분자에 숫자를 더해 0이 됨을 방지하는 generalization 방법 존재"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operational-giving",
   "metadata": {},
   "source": [
    "> **2) Trade-off**   \n",
    "> 작은 n은 카운트는 잘 되나, 근사 정확도가 현실 확률분포와 멀어짐   \n",
    "> 큰 n은 모델 성능이 높아지나, 카운트 확률이 작아져 희소 문제가 심각해짐 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "whole-warrant",
   "metadata": {},
   "source": [
    "# 4. Domain 코퍼스 수집\n",
    "분야에 따라 특정 단어의 확률 분포가 다름   \n",
    "도메인 코퍼스가 다르면 모델 성능도 비약적으로 다름"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innovative-degree",
   "metadata": {},
   "source": [
    "# 5. Neural Network Based Language Model\n",
    "대안으로 **인공 신경망** 언어 모델 사용"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
