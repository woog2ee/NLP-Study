{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cross-maine",
   "metadata": {},
   "source": [
    "# 1. PPL\n",
    "모델 내부 평가 지표이자 '헷갈리는 정도'로 해석   \n",
    "최소화될 때 문장 확률이 최대화되나, 이 경우 반드시 사람이 느끼기 좋은 언어 모델인 것은 아님\n",
    "$$PPL(W) = P(w_{1}, w_{2}, w_{3}, ..., w_{N})^{-\\frac{1}{N}} = \\sqrt[N]{\\frac{1}{P(w_{1}, w_{2}, w_{3}, ..., w_{N})}}$$   \n",
    "\n",
    "문장 확률 chain rule\n",
    "$$PPL(W) = \\sqrt[N]{\\frac{1}{P(w_{1}, w_{2}, w_{3}, ..., w_{N})}} = \\sqrt[N]{\\frac{1}{\\prod_{i=1}^{N}P(w_{i}|w_{1}, w_{2}, ..., w_{i-1})}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "middle-payday",
   "metadata": {},
   "source": [
    "# 2. Branching factor\n",
    "PPL은 특정 시점에서 몇 개 선택지로 고민하는지 뜻하는 분기 계수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guilty-authorization",
   "metadata": {},
   "source": [
    "# 3. 기존 언어 모델 vs. 인공 신경망 언어 모델\n",
    "페이스북 AI 연구팀의 PPL 성능 테스트   \n",
    "\n",
    "Model|Perplexity\n",
    ":----|:---:\n",
    "Interpolated Kneser-Ney 5-gram (Chelba et al., 2013)|67.6\n",
    "RNN-1024 + MaxEnt 9-gram (Chelba et al., 2013)|51.3\n",
    "RNN-2048 + BlackOut sampling (Ji et al., 2015)|68.3\n",
    "Sparse Non-negative Matrix factorization (Shazeer et al., 2015)|52.9\n",
    "LSTM-2048 (Jozefowicz et al., 2016)|43.7\n",
    "2-layer LSTM-8192 (Jozefowicz et al., 2016)|30\n",
    "**Ours small** (LSTM-2048)|43.9\n",
    "**Ours large** (2-layer LSTM-2048)|39.8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
